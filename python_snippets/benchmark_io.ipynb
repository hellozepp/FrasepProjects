{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Pandas vs Cudf\n",
    "- Using *timeit*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System details"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/sh: nvidia-smi: command not found\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processor       : 0\n",
      "vendor_id       : GenuineIntel\n",
      "cpu family      : 6\n",
      "model           : 79\n",
      "model name      : Intel(R) Xeon(R) CPU E5-2686 v4 @ 2.30GHz\n",
      "stepping        : 1\n",
      "microcode       : 0xb000038\n",
      "cpu MHz         : 2699.804\n",
      "cache size      : 46080 KB\n",
      "physical id     : 0\n",
      "siblings        : 16\n",
      "core id         : 0\n",
      "cpu cores       : 8\n",
      "apicid          : 0\n",
      "initial apicid  : 0\n",
      "fpu             : yes\n",
      "fpu_exception   : yes\n",
      "cpuid level     : 13\n",
      "wp              : yes\n",
      "\u001b[K:\u001b[K         : fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology aperfmperf eagerfpu pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt tsc_deadline_timer aes xsave avx f16c rdrand hy\u001b[7m/proc/cpuinfo\u001b[m\u001b[K\u0007"
     ]
    }
   ],
   "source": [
    "!less /proc/cpuinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installations\n",
    "Install our v3io-generator to create our 1gb dataset for the benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -i https://test.pypi.org/simple/ v3io-generator --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pytimeparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/ed/2fd5337ed405c4258dde1254e60f4e8ef9f1787576c0a2cd0d750b1716a6/Faker-2.0.3-py2.py3-none-any.whl (892kB)\n",
      "\u001b[K     |████████████████████████████████| 901kB 35.5MB/s eta 0:00:01��██████████████████▋           | 573kB 35.5MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six>=1.10 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from faker) (1.12.0)\n",
      "Requirement already satisfied: python-dateutil>=2.4 in /home/ec2-user/anaconda3/lib/python3.7/site-packages (from faker) (2.8.0)\n",
      "Collecting text-unidecode==1.3 (from faker)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/a5/c0b6468d3824fe3fde30dbb5e1f687b291608f9473681bbf7dabbf5a87d7/text_unidecode-1.3-py2.py3-none-any.whl (78kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 35.1MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: text-unidecode, faker\n",
      "Successfully installed faker-2.0.3 text-unidecode-1.3\n"
     ]
    }
   ],
   "source": [
    "!pip install faker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark configurations\n",
    "metric_names = ['cpu_utilization', 'latency', 'packet_loss', 'throughput']\n",
    "nlargest = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "# Generator\n",
    "from v3io_generator import metrics_generator, deployment_generator\n",
    "\n",
    "# Dataframes\n",
    "#import cudf\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data source\n",
    "Using our V3IO-Generator we will create a timeseries network-operations dataset for 100 companies including 4 metrics (cpu utilization, latency, throughput, packet loss).\n",
    "\n",
    "We will then write the dataset to a json file to be used as our source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>cpu_utilization</th>\n",
       "      <th>latency</th>\n",
       "      <th>packet_loss</th>\n",
       "      <th>throughput</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Stout_and_Sons</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>King_Group</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Davidson-Casey</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Stewart__Mitchell_and_Davies</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Pierce_and_Sons</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        company  cpu_utilization  latency  packet_loss  \\\n",
       "0                Stout_and_Sons                0        0            0   \n",
       "1                    King_Group                0        0            0   \n",
       "2                Davidson-Casey                0        0            0   \n",
       "3  Stewart__Mitchell_and_Davies                0        0            0   \n",
       "4               Pierce_and_Sons                0        0            0   \n",
       "\n",
       "   throughput  \n",
       "0           0  \n",
       "1           0  \n",
       "2           0  \n",
       "3           0  \n",
       "4           0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create meta-data factory\n",
    "dep_gen = deployment_generator.deployment_generator()\n",
    "faker=dep_gen.get_faker()\n",
    "\n",
    "# Design meta-data\n",
    "dep_gen.add_level(name='company',number=100,level_type=faker.company)\n",
    "\n",
    "# Generate deployment structure\n",
    "deployment_df = dep_gen.generate_deployment()\n",
    "\n",
    "# Setup initial values\n",
    "for metric in metric_names:\n",
    "    deployment_df[metric] = 0\n",
    "\n",
    "deployment_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_configuration = yaml.safe_load(\"\"\"\n",
    "errors: {length_in_ticks: 50, rate_in_ticks: 150}\n",
    "timestamps: {interval: 5s, stochastic_interval: false}\n",
    "metrics:\n",
    "  cpu_utilization:\n",
    "    accuracy: 2\n",
    "    distribution: normal\n",
    "    distribution_params: {mu: 70, noise: 0, sigma: 10}\n",
    "    is_threshold_below: true\n",
    "    past_based_value: false\n",
    "    produce_max: false\n",
    "    produce_min: false\n",
    "    validation:\n",
    "      distribution: {max: 1, min: -1, validate: false}\n",
    "      metric: {max: 100, min: 0, validate: true}\n",
    "  latency:\n",
    "    accuracy: 2\n",
    "    distribution: normal\n",
    "    distribution_params: {mu: 0, noise: 0, sigma: 5}\n",
    "    is_threshold_below: true\n",
    "    past_based_value: false\n",
    "    produce_max: false\n",
    "    produce_min: false\n",
    "    validation:\n",
    "      distribution: {max: 1, min: -1, validate: false}\n",
    "      metric: {max: 100, min: 0, validate: true}\n",
    "  packet_loss:\n",
    "    accuracy: 0\n",
    "    distribution: normal\n",
    "    distribution_params: {mu: 0, noise: 0, sigma: 2}\n",
    "    is_threshold_below: true\n",
    "    past_based_value: false\n",
    "    produce_max: false\n",
    "    produce_min: false\n",
    "    validation:\n",
    "      distribution: {max: 1, min: -1, validate: false}\n",
    "      metric: {max: 50, min: 0, validate: true}\n",
    "  throughput:\n",
    "    accuracy: 2\n",
    "    distribution: normal\n",
    "    distribution_params: {mu: 250, noise: 0, sigma: 20}\n",
    "    is_threshold_below: false\n",
    "    past_based_value: false\n",
    "    produce_max: false\n",
    "    produce_min: false\n",
    "    validation:\n",
    "      distribution: {max: 1, min: -1, validate: false}\n",
    "      metric: {max: 300, min: 0, validate: true}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "met_gen = metrics_generator.Generator_df(metrics_configuration, \n",
    "                                         user_hierarchy=deployment_df, \n",
    "                                         initial_timestamp=time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = '/tmp/ops.logs'\n",
    "metrics = met_gen.generate_range(start_time=datetime.datetime.now(),\n",
    "                                 end_time=datetime.datetime.now()+datetime.timedelta(hours=62),\n",
    "                                 as_df=True,\n",
    "                                 as_iterator=False)\n",
    "\n",
    "# Generate file from metrics\n",
    "with open(source_file, 'w') as f:\n",
    "    metrics_batch = metrics\n",
    "    metrics_batch.to_json(f,\n",
    "                          orient='records',\n",
    "                          lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target file size validation\n",
    "Set target size (in MB) for the test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 0\n",
      "drwxr-xr-x 2 50 nogroup    0 Jul 22 11:32 .ipynb_checkpoints\n",
      "-rw-r--r-- 1 50 nogroup 1.2G Jul 22 07:17 ops-1gb.logs\n",
      "-rw-r--r-- 1 50 nogroup 1.2G Jul 22 11:40 ops.logs\n"
     ]
    }
   ],
   "source": [
    "!ls -lah data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"company\":\"Rios__Pope_and_Baird\",\"cpu_utilization\":70.6942165035,\"cpu_utilization_is_error\":false,\"latency\":3.1373003261,\"latency_is_error\":false,\"packet_loss\":0.0,\"packet_loss_is_error\":false,\"throughput\":249.7207880994,\"throughput_is_error\":false,\"timestamp\":1563795193534}\n",
      "{\"company\":\"Ross__Calderon_and_Brown\",\"cpu_utilization\":56.540474522,\"cpu_utilization_is_error\":false,\"latency\":0.0,\"latency_is_error\":false,\"packet_loss\":0.0,\"packet_loss_is_error\":false,\"throughput\":261.9362588938,\"throughput_is_error\":false,\"timestamp\":1563795193534}\n",
      "{\"company\":\"Jackson_PLC\",\"cpu_utilization\":75.7476859549,\"cpu_utilization_is_error\":false,\"latency\":0.0,\"latency_is_error\":false,\"packet_loss\":1.3991427041,\"packet_loss_is_error\":false,\"throughput\":221.8819458316,\"throughput_is_error\":false,\"timestamp\":1563795193534}\n",
      "{\"company\":\"Reyes_Group\",\"cpu_utilization\":61.4657850595,\"cpu_utilization_is_error\":false,\"latency\":0.0,\"latency_is_error\":false,\"packet_loss\":1.7039267608,\"packet_loss_is_error\":false,\"throughput\":232.4317426357,\"throughput_is_error\":false,\"timestamp\":1563795193534}\n",
      "{\"company\":\"Carr-Reyes\",\"cpu_utilization\":49.9688296158,\"cpu_utilization_is_error\":false,\"latency\":0.4559851085,\"latency_is_error\":false,\"packet_loss\":0.0,\"packet_loss_is_error\":false,\"throughput\":276.0540712289,\"throughput_is_error\":false,\"timestamp\":1563795193534}\n",
      "{\"company\":\"Wilson_and_Sons\",\"cpu_utilization\":66.0718786965,\"cpu_utilization_is_error\":false,\"latency\":0.0,\"latency_is_error\":false,\"packet_loss\":0.2971395649,\"packet_loss_is_error\":false,\"throughput\":264.7801359998,\"throughput_is_error\":false,\"timestamp\":1563795193534}\n",
      "{\"company\":\"Nolan__Norton_and_Best\",\"cpu_utilization\":63.0572487273,\"cpu_utilization_is_error\":false,\"latency\":0.0,\"latency_is_error\":false,\"packet_loss\":0.0,\"packet_loss_is_error\":false,\"throughput\":264.033448601,\"throughput_is_error\":false,\"timestamp\":1563795193534}\n",
      "{\"company\":\"Brandt_LLC\",\"cpu_utilization\":90.6382973539,\"cpu_utilization_is_error\":false,\"latency\":1.9411864095,\"latency_is_error\":false,\"packet_loss\":2.527867727,\"packet_loss_is_error\":false,\"throughput\":232.8742238776,\"throughput_is_error\":false,\"timestamp\":1563795193534}\n",
      "{\"company\":\"Williams-Collins\",\"cpu_utilization\":64.1690341745,\"cpu_utilization_is_error\":false,\"latency\":0.0,\"latency_is_error\":false,\"packet_loss\":3.2983607178,\"packet_loss_is_error\":false,\"throughput\":264.0176356426,\"throughput_is_error\":false,\"timestamp\":1563795193534}\n",
      "{\"company\":\"Williams__Hutchinson_and_Harrison\",\"cpu_utilization\":60.6966740664,\"cpu_utilization_is_error\":false,\"latency\":0.0,\"latency_is_error\":false,\"packet_loss\":3.1742385435,\"packet_loss_is_error\":false,\"throughput\":230.875976139,\"throughput_is_error\":false,\"timestamp\":1563795193534}\n"
     ]
    }
   ],
   "source": [
    "!head data/ops.logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark\n",
    "\n",
    "### Flow\n",
    "- Read file\n",
    "- Compute aggregations\n",
    "- get nlargest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_file = source_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.44 s ± 23.1 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# Read file\n",
    "gdf = cudf.read_json(benchmark_file, lines=True)\n",
    "\n",
    "# Perform aggregation\n",
    "ggdf = gdf.groupby(['company']).\\\n",
    "            agg({k: ['min', 'max', 'mean'] for k in metric_names})\n",
    "\n",
    "# Get N Largest (From original df)\n",
    "raw_nlargest = gdf.nlargest(nlargest, 'cpu_utilization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43.4 s ± 627 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "# Read file\n",
    "pdf = pd.read_json(benchmark_file, lines=True)\n",
    "\n",
    "# Perform aggregation\n",
    "gpdf = pdf.groupby(['company']).\\\n",
    "            agg({k: ['min', 'max', 'mean'] for k in metric_names})\n",
    "\n",
    "# Get N Largest (From original df)\n",
    "raw_nlargest = pdf.nlargest(nlargest, 'cpu_utilization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test loading times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2 s ± 120 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gdf = cudf.read_json(benchmark_file, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.1 s ± 651 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "gdf = pd.read_json(benchmark_file, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test aggregation\n",
    "Load the files to memory so we can %timeit on the aggregations only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = cudf.read_json(benchmark_file, lines=True)\n",
    "pdf = pd.read_json(benchmark_file, lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212 ms ± 14.9 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "ggdf = gdf.groupby(['company']).\\\n",
    "            agg({k: ['min', 'max', 'mean'] for k in metric_names})\n",
    "raw_nlargest = gdf.nlargest(nlargest, 'cpu_utilization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.17 s ± 72.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "gpdf = pdf.groupby(['company']).\\\n",
    "            agg({k: ['min', 'max', 'mean'] for k in metric_names})\n",
    "raw_nlargest = pdf.nlargest(nlargest, 'cpu_utilization')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
